{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Training\n",
    "\n",
    "This is a simple Deep Learning Model Training Sample using Keras High Level API.\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python which contains a set of helper methods and libraries to define neural networks. \n",
    "\n",
    "Keras also comes with a access to some certain set of open data set for training purposes and Keras also provides some utility methods for pre-processing training data. \n",
    "\n",
    "Keras is self is a high level API so it needs a backend, it can work on Tensorflow, CNTK and Theano.\n",
    "\n",
    "In following example, we will go over training a model with famous MNIST (hand-written digits) data set to create a DL model which can predict hand written digits. \n",
    "\n",
    "- Good visual ilustration of the model we will build\n",
    "http://scs.ryerson.ca/~aharley/vis/conv/\n",
    "\n",
    "First, we start importing required libraries to start with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Database - Handwritten digits (0-9)\n",
    "\n",
    "On this tutorial we will use Python* to implement one Convolutional Neural Network - a simplified version of LeNet - that will recognized Handwritten digits. A project like this one, using the MNIST dataset is considered as the \"Hello World\" of Machine Learning.\n",
    "\n",
    "We will use Keras*, TensorFlow* and the MNIST database.\n",
    "\n",
    "According to the description on their website, \"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\"*\n",
    "\n",
    "We will use TensorFlow as the backend for Keras. TensorFlow is an open source software library for high performance numerical computation.\n",
    "\n",
    "The MNIST database is a large database of handwritten digits that is commonly used for training various image processing systems. MNIST database is also available as a Keras dataset, with 60k 28x28 images of the 10 digits along with a test set of 10k images, so it is very easy to import and use it on our code.\n",
    "\n",
    "One good visual and interactive reference on what we are developing can be found here. The basic difference between our code and this interactive sample is the number and size of convolutional and fully-connected layers (LeNet uses two of each, we will use a single one, to reduce training time). We also adjusted the layers size to balance between accuracy and training time. We are achieving 98,54% of accuracy with less than 2 minutes training time on an Intel® Core™ processor.\n",
    "\n",
    "This code can also be optimized by several ways to increase accuracy, and we would like to invite you to explore this later, changing the number of epochs, filters, fully-connected neurons and also including additional convolutional and fully connected layers. You can also use flattening, dropout and batch normalization layers. Other optimization techniques can also be applied, so feel free to use this tutorial code as a base to explore those optimization techniques.\n",
    "\n",
    "In a nutshell, the convolutional and pooling layers are responsible for extracting a set of features from the input images, and the fully-connected layers are responsible for classification.\n",
    "\n",
    "Convolutional layers applies a set of filters to the input image to extract important features from the image. The filters are small matrixes also called image kernels that can be repeatedly applied to the input image (\"sliding\" the filter on the image). You may already used those filters on traditional image processing applications such as GIMP (i.e. blurring, sharpening or embossing). This article gives a good overview on image kernels with some live experiments. Each filter will generate a new image that will be the input for the next layer, typically a pooling layer.\n",
    "\n",
    "Pooling layers reduces the spatial size of the image (downsampling), reducing the computation in the network and also controlling overfitting.\n",
    "\n",
    "Fully connected layers are traditional Neural Network layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Install Following Packages for Python\n",
    "\n",
    "```\n",
    "tensorflow\n",
    "keras\n",
    "```\n",
    "\n",
    "Install Commands\n",
    "\n",
    "```\n",
    "pip3 install tensorflow\n",
    "pip3 install keras\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Sequential Network Model https://keras.io/models/sequential/\n",
    "from keras.models import Sequential\n",
    "# Core Layers https://keras.io/layers/core/\n",
    "# Dense: densely-connected NN layer, to be used as classification layer\n",
    "# Flatten: layer to flatten the convolutional layers\n",
    "\n",
    "from keras.layers import Dense, Flatten\n",
    "# Convolutional Layers https://keras.io/layers/convolutional/\n",
    "# Conv2D: 2D convolution Layer\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "# Pooling Layer: https://keras.io/layers/pooling/\n",
    "# MaxPooling2D: Max pooling operation for spatial data\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "# Utilities https://keras.io/utils/\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# MNIST Dataset https://keras.io/datasets/\n",
    "# Dataset of 60,000 28x28 handwritten images of the 10 digits, along with a test set of 10,000 images.\n",
    "from keras.datasets import mnist\n",
    "\n",
    "## Keras Backend\n",
    "from keras import backend as K\n",
    "\n",
    "## Util lib os\n",
    "import os, argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "# The original freeze_graph function\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST Dataset and Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we will first load the dataset. using mnist interface. Then, we go with pre-processing data set to make it ready to be accepted in Input layer for DL.\n",
    "\n",
    "Then, we make sure type is float, DL models only uses floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data set in two sets: Trainning (60K IMAGES) and Testing (10k images)\n",
    "(train_dataset, train_classes),(test_dataset, test_classes) = mnist.load_data()\n",
    "\n",
    "# Adjust datasets to TensorFlow\n",
    "# Reduce image channels from 3 to 1\n",
    "train_dataset = train_dataset.reshape(train_dataset.shape[0], 28, 28, 1)\n",
    "test_dataset = test_dataset.reshape(test_dataset.shape[0], 28, 28, 1)\n",
    "\n",
    "# Covert data from int8 to float32\n",
    "train_dataset = train_dataset.astype('float32')\n",
    "test_dataset = test_dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are doing normalization of the dataset. DL models, can work on normalized data a lot faster and accurate. heterogenous numbers tend to over-fit and hard to converge during training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to speed up processing time\n",
    "train_dataset = train_dataset / 255\n",
    "test_dataset = test_dataset / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this part, we convert output to a categorical class representation. During the training process, our model will try to converge certain values, mainly 0 or 1. However in this case we have 10 different category. Therefore, we create a tensor with 1D shape where training value only can be one of the values.\n",
    "\n",
    "- e.g. label of training input is 2.\n",
    "- DL output/class is [0., 0., 1., ....]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class data from numerical to categorical\n",
    "train_classes = np_utils.to_categorical(train_classes, 10)\n",
    "test_classes = np_utils.to_categorical(test_classes, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Keras CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the final part where we create a basic Convolutional Neural Network with using Keras Layers. \n",
    "\n",
    "Below is a very basic CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Convolutional Neural Network\n",
    "cnn = Sequential()\n",
    "\n",
    "# Add the convolutional layer with 32 filters, 3x3 convolution window,\n",
    "# 28 x 28 x 1 pixels imput array and Rectified Linear Unit activation function\n",
    "cnn.add(Conv2D(32, (3,3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "\n",
    "# Add one Pooling layer with default 2x2 size\n",
    "cnn.add(MaxPooling2D())\n",
    "\n",
    "# Add one flattening layer to convert the output matrix to a vector to be the Deep Neural Network input\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Add one hidden layer with 128 neurons and Rectified Linear Unit activation function\n",
    "cnn.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "# Add the output layer with 10 neurons (one for each class) with Softmax as the activation function\n",
    "cnn.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the last part, where loss function, optimizer and metrics has been defined for training process. \n",
    "\n",
    "`.fit` method used to start training process with provided training and label data.\n",
    "\n",
    "When, fit finished your model is ready to predict. \n",
    "\n",
    "`.evaluate` used to check results with test data set and see the accuracy of your model with a data set never seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model to Make it Ready for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN with:\n",
    "#  - Categorical crossentropy as the loss function\n",
    "#  - Adam optimizer\n",
    "#  - Accuracy as the results evaluation metric\n",
    "cnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 29s 480us/step - loss: 0.2298 - acc: 0.9335 - val_loss: 0.0843 - val_acc: 0.9739\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.0674 - acc: 0.9803 - val_loss: 0.0498 - val_acc: 0.9828\n",
      "10000/10000 [==============================] - 1s 134us/step\n",
      "Accuracy = 98.28%\n"
     ]
    }
   ],
   "source": [
    "# Execute the training on 5 epochs, validating the generated model with test dataset on each epoch\n",
    "cnn.fit(train_dataset, train_classes, batch_size = 128, epochs = 2, validation_data = (test_dataset, test_classes))\n",
    "\n",
    "# Extract and print the Accuracy results\n",
    "result = cnn.evaluate(test_dataset, test_classes)\n",
    "print ('Accuracy = ' + str(result[1] * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Froze & Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "frozen = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [\"dense_2_1/Softmax:0\"])\n",
    "\n",
    "graph_io.write_graph(frozen, './models/digit_recognizer_model/', 'inference_graph.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Froze Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'dense_2_1/Softmax:0' shape=(?, 10) dtype=float32>]\n",
      "[<tf.Tensor 'conv2d_1_input_1:0' shape=(?, 28, 28, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('cnn_sample_model/digit_recognizer.h5')\n",
    "print(model.outputs)\n",
    "# [<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>]\n",
    "print(model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-33036d3dd832>:29: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 58 variables.\n",
      "INFO:tensorflow:Converted 58 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnn_sample_model/digit_recognizer.pb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to ./model/tf_model.pb\n",
    "tf.train.write_graph(frozen_graph, \"cnn_sample_model\", \"digit_recognizer.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Predict with Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/intel/Workshop2/cnn_sample_model/digit_recognizer.pb\n",
      "\t- Path for generated IR: \t/home/intel/Workshop2/.\n",
      "\t- IR output name: \tdigit_recognizer\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "[ FRAMEWORK ERROR ]  Cannot load input model: Unable to open table file /home/intel/Workshop2/cnn_sample_model/digit_recognizer.h5: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    }
   ],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "--input_model \"cnn_sample_model/digit_recognizer.pb\" \\\n",
    "--input_checkpoint \"cnn_sample_model/digit_recognizer.chptk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/fsausset/57b99a3db5e1a05569845894ec385eef\n",
    "# https://github.com/alanswx/keras_to_tensorflow/blob/master/convertkeras.py\n",
    "# https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/python/tools/freeze_graph.py\n",
    "# https://stackoverflow.com/questions/45466020/how-to-export-keras-h5-to-tensorflow-pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model for Intel(R) Distribution of OpenVINO(TM) Toolkit Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
