{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Training\n",
    "\n",
    "This is a simple Deep Learning Model Training Sample using Keras High Level API.\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python which contains a set of helper methods and libraries to define neural networks. \n",
    "\n",
    "Keras also comes with a access to some certain set of open data set for training purposes and Keras also provides some utility methods for pre-processing training data. \n",
    "\n",
    "Keras is self is a high level API so it needs a backend, it can work on Tensorflow, CNTK and Theano.\n",
    "\n",
    "In following example, we will go over training a model with famous MNIST (hand-written digits) data set to create a DL model which can predict hand written digits. \n",
    "\n",
    "- Good visual ilustration of the model we will build\n",
    "http://scs.ryerson.ca/~aharley/vis/conv/\n",
    "\n",
    "First, we start importing required libraries to start with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Database - Handwritten digits (0-9)\n",
    "\n",
    "On this tutorial we will use Python* to implement one Convolutional Neural Network - a simplified version of LeNet - that will recognized Handwritten digits. A project like this one, using the MNIST dataset is considered as the \"Hello World\" of Machine Learning.\n",
    "\n",
    "We will use Keras*, TensorFlow* and the MNIST database.\n",
    "\n",
    "According to the description on their website, \"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\"*\n",
    "\n",
    "We will use TensorFlow as the backend for Keras. TensorFlow is an open source software library for high performance numerical computation.\n",
    "\n",
    "The MNIST database is a large database of handwritten digits that is commonly used for training various image processing systems. MNIST database is also available as a Keras dataset, with 60k 28x28 images of the 10 digits along with a test set of 10k images, so it is very easy to import and use it on our code.\n",
    "\n",
    "One good visual and interactive reference on what we are developing can be found here. The basic difference between our code and this interactive sample is the number and size of convolutional and fully-connected layers (LeNet uses two of each, we will use a single one, to reduce training time). We also adjusted the layers size to balance between accuracy and training time. We are achieving 98,54% of accuracy with less than 2 minutes training time on an Intel® Core™ processor.\n",
    "\n",
    "This code can also be optimized by several ways to increase accuracy, and we would like to invite you to explore this later, changing the number of epochs, filters, fully-connected neurons and also including additional convolutional and fully connected layers. You can also use flattening, dropout and batch normalization layers. Other optimization techniques can also be applied, so feel free to use this tutorial code as a base to explore those optimization techniques.\n",
    "\n",
    "In a nutshell, the convolutional and pooling layers are responsible for extracting a set of features from the input images, and the fully-connected layers are responsible for classification.\n",
    "\n",
    "Convolutional layers applies a set of filters to the input image to extract important features from the image. The filters are small matrixes also called image kernels that can be repeatedly applied to the input image (\"sliding\" the filter on the image). You may already used those filters on traditional image processing applications such as GIMP (i.e. blurring, sharpening or embossing). This article gives a good overview on image kernels with some live experiments. Each filter will generate a new image that will be the input for the next layer, typically a pooling layer.\n",
    "\n",
    "Pooling layers reduces the spatial size of the image (downsampling), reducing the computation in the network and also controlling overfitting.\n",
    "\n",
    "Fully connected layers are traditional Neural Network layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Install Following Packages for Python\n",
    "\n",
    "```\n",
    "tensorflow\n",
    "keras\n",
    "```\n",
    "\n",
    "Install Commands\n",
    "\n",
    "```\n",
    "pip3 install tensorflow\n",
    "pip3 install keras\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Sequential Network Model https://keras.io/models/sequential/\n",
    "from keras.models import Sequential\n",
    "# Core Layers https://keras.io/layers/core/\n",
    "# Dense: densely-connected NN layer, to be used as classification layer\n",
    "# Flatten: layer to flatten the convolutional layers\n",
    "\n",
    "from keras.layers import Dense, Flatten\n",
    "# Convolutional Layers https://keras.io/layers/convolutional/\n",
    "# Conv2D: 2D convolution Layer\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "# Pooling Layer: https://keras.io/layers/pooling/\n",
    "# MaxPooling2D: Max pooling operation for spatial data\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "# Utilities https://keras.io/utils/\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# MNIST Dataset https://keras.io/datasets/\n",
    "# Dataset of 60,000 28x28 handwritten images of the 10 digits, along with a test set of 10,000 images.\n",
    "from keras.datasets import mnist\n",
    "\n",
    "## Keras Backend\n",
    "from keras import backend as K\n",
    "\n",
    "## Util lib os\n",
    "import os, argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "# The original freeze_graph function\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST Dataset and Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we will first load the dataset. using mnist interface. Then, we go with pre-processing data set to make it ready to be accepted in Input layer for DL.\n",
    "\n",
    "Then, we make sure type is float, DL models only uses floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data set in two sets: Trainning (60K IMAGES) and Testing (10k images)\n",
    "(train_dataset, train_classes),(test_dataset, test_classes) = mnist.load_data()\n",
    "\n",
    "# Adjust datasets to TensorFlow\n",
    "# Reduce image channels from 3 to 1\n",
    "train_dataset = train_dataset.reshape(train_dataset.shape[0], 28, 28, 1)\n",
    "test_dataset = test_dataset.reshape(test_dataset.shape[0], 28, 28, 1)\n",
    "\n",
    "# Covert data from int8 to float32\n",
    "train_dataset = train_dataset.astype('float32')\n",
    "test_dataset = test_dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are doing normalization of the dataset. DL models, can work on normalized data a lot faster and accurate. heterogenous numbers tend to over-fit and hard to converge during training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to speed up processing time\n",
    "train_dataset = train_dataset / 255\n",
    "test_dataset = test_dataset / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this part, we convert output to a categorical class representation. During the training process, our model will try to converge certain values, mainly 0 or 1. However in this case we have 10 different category. Therefore, we create a tensor with 1D shape where training value only can be one of the values.\n",
    "\n",
    "- e.g. label of training input is 2.\n",
    "- DL output/class is [0., 0., 1., ....]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class data from numerical to categorical\n",
    "train_classes = np_utils.to_categorical(train_classes, 10)\n",
    "test_classes = np_utils.to_categorical(test_classes, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Keras CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the final part where we create a basic Convolutional Neural Network with using Keras Layers. \n",
    "\n",
    "Below is a very basic CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Convolutional Neural Network\n",
    "cnn = Sequential()\n",
    "\n",
    "# Add the convolutional layer with 32 filters, 3x3 convolution window,\n",
    "# 28 x 28 x 1 pixels imput array and Rectified Linear Unit activation function\n",
    "cnn.add(Conv2D(32, (3,3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "\n",
    "# Add one Pooling layer with default 2x2 size\n",
    "cnn.add(MaxPooling2D())\n",
    "\n",
    "# Add one flattening layer to convert the output matrix to a vector to be the Deep Neural Network input\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Add one hidden layer with 128 neurons and Rectified Linear Unit activation function\n",
    "cnn.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "# Add the output layer with 10 neurons (one for each class) with Softmax as the activation function\n",
    "cnn.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the last part, where loss function, optimizer and metrics has been defined for training process. \n",
    "\n",
    "`.fit` method used to start training process with provided training and label data.\n",
    "\n",
    "When, fit finished your model is ready to predict. \n",
    "\n",
    "`.evaluate` used to check results with test data set and see the accuracy of your model with a data set never seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model to Make it Ready for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN with:\n",
    "#  - Categorical crossentropy as the loss function\n",
    "#  - Adam optimizer\n",
    "#  - Accuracy as the results evaluation metric\n",
    "cnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 25s 425us/step - loss: 0.2959 - acc: 0.9181 - val_loss: 0.1175 - val_acc: 0.9657\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 25s 421us/step - loss: 0.0934 - acc: 0.9734 - val_loss: 0.0747 - val_acc: 0.9768\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 25s 422us/step - loss: 0.0616 - acc: 0.9818 - val_loss: 0.0560 - val_acc: 0.9819\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.0467 - acc: 0.9866 - val_loss: 0.0508 - val_acc: 0.9827\n",
      "10000/10000 [==============================] - 2s 162us/step\n",
      "Accuracy = 98.27%\n"
     ]
    }
   ],
   "source": [
    "# Execute the training on 5 epochs, validating the generated model with test dataset on each epoch\n",
    "cnn.fit(train_dataset, train_classes, batch_size = 256, epochs = 4, validation_data = (test_dataset, test_classes))\n",
    "\n",
    "# Extract and print the Accuracy results\n",
    "result = cnn.evaluate(test_dataset, test_classes)\n",
    "print ('Accuracy = ' + str(result[1] * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Froze & Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "cnn.save('./models/digit_recognizer.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Froze Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'dense_2_1/Softmax:0' shape=(?, 10) dtype=float32>]\n",
      "[<tf.Tensor 'conv2d_1_input_1:0' shape=(?, 28, 28, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./models/digit_recognizer.h5')\n",
    "print(model.outputs)\n",
    "print(model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 58 variables.\n",
      "INFO:tensorflow:Converted 58 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/digit_recognizer.pb'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to ./model/tf_model.pb\n",
    "tf.train.write_graph(frozen_graph, \"models\", \"digit_recognizer.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Predict with Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/intel/Workshop/models/digit_recognizer.pb\n",
      "\t- Path for generated IR: \t/home/intel/Workshop/models/FP32\n",
      "\t- IR output name: \tdigit_recognizer\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,28,28,1]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.1.1-83-g28dfbfd\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/intel/Workshop/models/FP32/digit_recognizer.xml\n",
      "[ SUCCESS ] BIN file: /home/intel/Workshop/models/FP32/digit_recognizer.bin\n",
      "[ SUCCESS ] Total execution time: 3.83 seconds. \n"
     ]
    }
   ],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "--input_model 'models/digit_recognizer.pb' \\\n",
    "--input_shape [1,28,28,1] \\\n",
    "--output_dir 'models/FP32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model for Intel(R) Distribution of OpenVINO(TM) Toolkit Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Shape:  [1, 1, 28, 28]\n",
      "Frame Shape:  (59, 57)\n",
      "In Frame Shape:  (1, 28, 28)\n",
      "Result Vector:  [[4.51112550e-11 1.30003126e-12 3.50218897e-07 8.21897328e-01\n",
      "  8.68001417e-14 1.78076923e-01 1.01418614e-07 5.44159093e-11\n",
      "  2.51088441e-05 1.98381201e-07]]\n",
      "Digit - 0  - Possibility 0.0\n",
      "Digit - 1  - Possibility 0.0\n",
      "Digit - 2  - Possibility 0.0\n",
      "Digit - 3  - Possibility 0.8219\n",
      "Digit - 4  - Possibility 0.0\n",
      "Digit - 5  - Possibility 0.17808\n",
      "Digit - 6  - Possibility 0.0\n",
      "Digit - 7  - Possibility 0.0\n",
      "Digit - 8  - Possibility 3e-05\n",
      "Digit - 9  - Possibility 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time:  0.00152  Seconds\n"
     ]
    }
   ],
   "source": [
    "# Press (SHIFT + Enter or Click on Run Button)\n",
    "# Required Libraries Imported\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Import Required OpenVINO(TM) Libraries\n",
    "from openvino.inference_engine import IEPlugin, IENetwork\n",
    "\n",
    "def createPlugin(target_device, extension_list):\n",
    "    # Plugin initialization for specified device. We will be targeting CPU initially.\n",
    "    plugin = IEPlugin(device=target_device)\n",
    "\n",
    "    # Loading additional kernel extension libraries for the CPU\n",
    "    if target_device == 'CPU':\n",
    "        for extension in extension_list:\n",
    "            plugin.add_cpu_extension('/home/intel/inference_engine_samples_build/intel64/Release/lib/libcpu_extension.so')\n",
    "\n",
    "    return plugin\n",
    "\n",
    "\n",
    "# Press (SHIFT + Enter or Click on Run Button)\n",
    "def createNetwork(model_xml, model_bin, plugin):\n",
    "    \n",
    "    # Importing network weights from IR models.\n",
    "    net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "    # Some layers in IR models may be unsupported by some plugins so we check if there any unsupported layers\n",
    "    if \"CPU\" in plugin.device:\n",
    "        supported_layers = plugin.get_supported_layers(net)\n",
    "        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "        if len(not_supported_layers) != 0:\n",
    "            print(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                      format(plugin.device, ', '.join(not_supported_layers)))\n",
    "            return None\n",
    "    return net\n",
    "\n",
    "# Press (SHIFT + Enter or Click on Run Button)\n",
    "def loadNetwork(plugin, net):\n",
    "    # Loading IR model to the plugin.\n",
    "    exec_net = plugin.load(network=net, num_requests=2)\n",
    "    \n",
    "    # Getting the input and outputs of the network\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    \n",
    "    out_blob = next(iter(net.outputs))\n",
    "    \n",
    "    return exec_net,input_blob,out_blob\n",
    "\n",
    "# Press (SHIFT + Enter or Click on Run Button)\n",
    "def preprocessImage(img_path, net, input_blob):\n",
    "    # Reading the frame from a jpeg file\n",
    "    frame = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Reshaping data\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    print('Model Shape: ', net.inputs[input_blob].shape)\n",
    "    print('Frame Shape: ', frame.shape)\n",
    "    in_frame = cv.resize(frame, (w, h))\n",
    "    in_frame = in_frame.reshape((1, w, h))\n",
    "    print('In Frame Shape: ', in_frame.shape)\n",
    "    # in_frame = in_frame.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "    in_frame = in_frame / 255\n",
    "    \n",
    "    return in_frame.reshape((n, c, h, w)),frame\n",
    "\n",
    "device=\"CPU\" \n",
    "model_xml='models/FP32/digit_recognizer.xml'\n",
    "model_bin='models/FP32/digit_recognizer.bin'\n",
    "image_file='images/hand_written_digit.png'\n",
    "\n",
    "# Get Plugin\n",
    "plugin = createPlugin(target_device=device, \n",
    "                      extension_list=['/home/intel/inference_engine_samples_build/intel64/Release/lib/libcpu_extension.so'])\n",
    "\n",
    "# Get Network\n",
    "net = createNetwork(model_xml, model_bin, plugin)\n",
    "\n",
    "# Get Executable Network, Input and Output Layer Information\n",
    "exec_net,input_blob,out_blob = loadNetwork(plugin, net)\n",
    "\n",
    "# Pre-process Image According to Input Layer\n",
    "in_frame, original_frame = preprocessImage(image_file, net, input_blob)\n",
    "\n",
    "# Starting the inference in async mode, which starts the inference in parallel\n",
    "inference_start = time.time()\n",
    "\n",
    "# Start Infering given Frame/Image\n",
    "exec_net.infer(inputs={input_blob: in_frame})\n",
    "\n",
    "# Getting the result of the network\n",
    "res = exec_net.requests[0].outputs[out_blob]\n",
    "\n",
    "print('Result Vector: ', res)\n",
    "for i, r in enumerate(res[0]):\n",
    "    print ('Digit - {}  - Possibility'.format(i), round(r, 5))\n",
    "\n",
    "inference_end = time.time()\n",
    "\n",
    "fig = plt.figure(dpi=50)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(cv.cvtColor(original_frame, cv.COLOR_BGR2RGB), interpolation='none')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print('Inference Time: ', round(inference_end - inference_start, 5), ' Seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources \n",
    "\n",
    "- https://gist.github.com/fsausset/57b99a3db5e1a05569845894ec385eef\n",
    "- https://github.com/alanswx/keras_to_tensorflow/blob/master/convertkeras.py\n",
    "- https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/python/tools/freeze_graph.py\n",
    "- https://stackoverflow.com/questions/45466020/how-to-export-keras-h5-to-tensorflow-pb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
